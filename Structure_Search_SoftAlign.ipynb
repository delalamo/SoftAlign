{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jtrinquier/SoftAlign/blob/main/Structure_Search_SoftAlign.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "PASMkwYTc_NB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c31dcf0-d0e1-4668-dee8-4bf02e551699",
        "cellView": "form"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting Bio\n",
            "  Downloading bio-1.8.0-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting biopython>=1.80 (from Bio)\n",
            "  Downloading biopython-1.85-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
            "Collecting gprofiler-official (from Bio)\n",
            "  Downloading gprofiler_official-1.0.0-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting mygene (from Bio)\n",
            "  Downloading mygene-3.2.2-py2.py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from Bio) (2.2.2)\n",
            "Requirement already satisfied: pooch in /usr/local/lib/python3.11/dist-packages (from Bio) (1.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from Bio) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from Bio) (4.67.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from biopython>=1.80->Bio) (2.0.2)\n",
            "Collecting biothings-client>=0.2.6 (from mygene->Bio)\n",
            "  Downloading biothings_client-0.4.1-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->Bio) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->Bio) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->Bio) (2025.2)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from pooch->Bio) (4.3.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from pooch->Bio) (24.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->Bio) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->Bio) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->Bio) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->Bio) (2025.6.15)\n",
            "Requirement already satisfied: httpx>=0.22.0 in /usr/local/lib/python3.11/dist-packages (from biothings-client>=0.2.6->mygene->Bio) (0.28.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->Bio) (1.17.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.22.0->biothings-client>=0.2.6->mygene->Bio) (4.9.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.22.0->biothings-client>=0.2.6->mygene->Bio) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.22.0->biothings-client>=0.2.6->mygene->Bio) (0.16.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.22.0->biothings-client>=0.2.6->mygene->Bio) (1.3.1)\n",
            "Requirement already satisfied: typing_extensions>=4.5 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.22.0->biothings-client>=0.2.6->mygene->Bio) (4.14.0)\n",
            "Downloading bio-1.8.0-py3-none-any.whl (321 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m321.1/321.1 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading biopython-1.85-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m76.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gprofiler_official-1.0.0-py3-none-any.whl (9.3 kB)\n",
            "Downloading mygene-3.2.2-py2.py3-none-any.whl (5.4 kB)\n",
            "Downloading biothings_client-0.4.1-py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m46.7/46.7 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: biopython, gprofiler-official, biothings-client, mygene, Bio\n",
            "Successfully installed Bio-1.8.0 biopython-1.85 biothings-client-0.4.1 gprofiler-official-1.0.0 mygene-3.2.2\n",
            "Collecting git+https://github.com/deepmind/dm-haiku\n",
            "  Cloning https://github.com/deepmind/dm-haiku to /tmp/pip-req-build-39mrr5oz\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/deepmind/dm-haiku /tmp/pip-req-build-39mrr5oz\n",
            "  Resolved https://github.com/deepmind/dm-haiku to commit 8f105828d3126decc62bafc9888d8049556b7bc6\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: absl-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from dm-haiku==0.0.15.dev0) (1.4.0)\n",
            "Collecting jmp>=0.0.2 (from dm-haiku==0.0.15.dev0)\n",
            "  Downloading jmp-0.0.4-py3-none-any.whl.metadata (8.9 kB)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.11/dist-packages (from dm-haiku==0.0.15.dev0) (2.0.2)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.11/dist-packages (from dm-haiku==0.0.15.dev0) (0.9.0)\n",
            "Downloading jmp-0.0.4-py3-none-any.whl (18 kB)\n",
            "Building wheels for collected packages: dm-haiku\n",
            "  Building wheel for dm-haiku (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for dm-haiku: filename=dm_haiku-0.0.15.dev0-py3-none-any.whl size=373949 sha256=dc50555cef2fec5b2408641a9d2bd2ea34c961bd5fba3738678b769bce9520c1\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-a4xp_war/wheels/86/29/0a/454c478e7217c383ee3d05aa43cbeff48284c23430f59d0c4f\n",
            "Successfully built dm-haiku\n",
            "Installing collected packages: jmp, dm-haiku\n",
            "Successfully installed dm-haiku-0.0.15.dev0 jmp-0.0.4\n",
            "Cloning into 'SoftAlign'...\n",
            "remote: Enumerating objects: 60, done.\u001b[K\n",
            "remote: Counting objects: 100% (8/8), done.\u001b[K\n",
            "remote: Compressing objects: 100% (6/6), done.\u001b[K\n",
            "remote: Total 60 (delta 4), reused 2 (delta 2), pack-reused 52 (from 2)\u001b[K\n",
            "Receiving objects: 100% (60/60), 3.44 MiB | 30.13 MiB/s, done.\n",
            "Resolving deltas: 100% (17/17), done.\n"
          ]
        }
      ],
      "source": [
        "# @title Import libraries\n",
        "! pip install Bio\n",
        "import jax\n",
        "!  pip install git+https://github.com/deepmind/dm-haiku\n",
        "import haiku as hk\n",
        "import jax.numpy as jnp\n",
        "from jax import vmap\n",
        "import numpy as np\n",
        "import time\n",
        "import numpy as np\n",
        "import time\n",
        "import os\n",
        "! git clone https://github.com/jtrinquier/SoftAlign.git\n",
        "import sys\n",
        "softalign_path = os.path.join(os.getcwd(), 'SoftAlign')\n",
        "\n",
        "# Add SoftAlign directory to sys.path if it's not already there\n",
        "if softalign_path not in sys.path:\n",
        "    sys.path.append(softalign_path)\n",
        "import ENCODING as enco\n",
        "import Score_align as score_\n",
        "import utils\n",
        "import Input_MPNN as inp"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import search"
      ],
      "metadata": {
        "id": "vgt_dDUU3-aZ"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üîç Input Options for Structure Preprocessing\n",
        "\n",
        "You can choose one of the following two input sources:\n",
        "\n",
        "1. **SCOPE Database (Precomputed Inputs)**  \n",
        "   Enable the checkbox to download and load preprocessed structural inputs from the SCOPE database. This is useful for benchmarking or testing.\n",
        "\n",
        "2. **Custom PDB Folder**  \n",
        "   If you want to use your own protein structures, disable the SCOPE option and provide the path to your folder containing `.pdb` files. The script will process all PDBs in that folder using `Input_MPNN`. You should also provide a list of chain_ids (default A), format should be pdbname, chain_id\n",
        "   \n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "MD7FJAOYHeE4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "K2qf1aNYJkta",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9dc40a4b-b506-4b63-a202-d81e45f496b0",
        "cellView": "form"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1DFWcUgPukTxWGPUxaeTM1kNEVNCkRgbO\n",
            "From (redirected): https://drive.google.com/uc?id=1DFWcUgPukTxWGPUxaeTM1kNEVNCkRgbO&confirm=t&uuid=4e421af2-2641-4394-8ef8-f25ec988c264\n",
            "To: /content/dicti_inputs_SCOPE_colab\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 236M/236M [00:01<00:00, 157MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded SCOPE database inputs.\n"
          ]
        }
      ],
      "source": [
        "# @title Choose input source: SCOPE database or Custom PDB folder\n",
        "use_scope_database = True  # @param {type:\"boolean\"}\n",
        "pdb_folder_path = \"pdb_files\"  # @param {type:\"string\"}\n",
        "chain_ids_file = \"\"  # @param {type:\"string\"}\n",
        "\n",
        "import os\n",
        "import pickle\n",
        "import csv\n",
        "import requests\n",
        "\n",
        "def load_chain_ids(chain_file_path):\n",
        "    \"\"\"Load a dictionary of {pdb_filename: chain_id}\"\"\"\n",
        "    chain_map = {}\n",
        "    with open(chain_file_path, 'r') as f:\n",
        "        reader = csv.reader(f, delimiter=\",\")\n",
        "        for row in reader:\n",
        "            if len(row) >= 2:\n",
        "                pdb_name = row[0].strip()\n",
        "                chain = row[1].strip()\n",
        "                chain_map[pdb_name] = chain\n",
        "    return chain_map\n",
        "\n",
        "def process_pdb_folder(pdb_folder, chain_file=None, default_chain='A'):\n",
        "    data = {}\n",
        "    chain_map = load_chain_ids(chain_file) if chain_file else {}\n",
        "    for filename in os.listdir(pdb_folder):\n",
        "        if filename.endswith(\".pdb\"):\n",
        "            pdb_path = os.path.join(pdb_folder, filename)\n",
        "            pdb_key = filename.replace(\".pdb\", \"\")\n",
        "            chain = chain_map.get(pdb_key, default_chain)\n",
        "            try:\n",
        "                coords, mask, chain_, res = inp.get_inputs_mpnn(pdb_path, chain=chain)\n",
        "                data[filename] = (coords, mask, chain_, res)\n",
        "                print(f\"Processed {filename} using chain {chain}\")\n",
        "            except Exception as e:\n",
        "                print(f\"Error processing {pdb_path}: {e}\")\n",
        "                continue\n",
        "\n",
        "    return data\n",
        "\n",
        "if use_scope_database:\n",
        "    try:\n",
        "        import gdown\n",
        "    except ImportError:\n",
        "        !pip install -q gdown\n",
        "        import gdown\n",
        "\n",
        "    gdown.download(id=\"1DFWcUgPukTxWGPUxaeTM1kNEVNCkRgbO\", output=\"dicti_inputs_SCOPE_colab\", quiet=False)\n",
        "    with open(\"dicti_inputs_SCOPE_colab\", 'rb') as f:\n",
        "        dicti_inputs = pickle.load(f)\n",
        "    print(\"Loaded SCOPE database inputs.\")\n",
        "else:\n",
        "    from Bio.PDB import PDBList\n",
        "\n",
        "    dicti_inputs = process_pdb_folder(pdb_folder_path, chain_file=chain_ids_file)\n",
        "    print(\"Processed custom PDB folder inputs.\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Selection: Alignment Strategy\n",
        "\n",
        "Select one of the two available alignment models for structural comparison:\n",
        "\n",
        "1. **Smith-Waterman**  \n",
        "\n",
        "\n",
        "2. **Softmax-Based**  \n",
        "\n",
        "\n",
        "Use the dropdown menu to select your model, and the corresponding parameters will be loaded automatically.\n",
        "\n"
      ],
      "metadata": {
        "id": "IOPFyXeHNXSH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "sZDv2NhXBYX7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "16d1de64-b904-423d-af87-cad05df07a72",
        "cellView": "form"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded parameters for Softmax model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-4-261426830.py:15: DeprecationWarning: Pickled array contains an aval with a named_shape attribute. This is deprecated and the code path supporting such avals will be removed. Please re-pickle the array.\n",
            "  params = pickle.load(open(params_path, \"rb\"))\n"
          ]
        }
      ],
      "source": [
        "# @title Choose Model Type\n",
        "model_type = \"Softmax\"  # @param [\"Smith-Waterman\", \"Softmax\"]\n",
        "params_path_sw = \"./SoftAlign/models/CONT_SW_05_T_3_1\"\n",
        "params_path_sft = \"./SoftAlign/models/CONT_SFT_06_T_3_1\"\n",
        "\n",
        "import pickle\n",
        "\n",
        "if model_type == \"Smith-Waterman\":\n",
        "    params_path = params_path_sw\n",
        "elif model_type == \"Softmax\":\n",
        "    params_path = params_path_sft\n",
        "else:\n",
        "    raise ValueError(\"Invalid model type selected.\")\n",
        "\n",
        "params = pickle.load(open(params_path, \"rb\"))\n",
        "print(f\"Loaded parameters for {model_type} model.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0MtEplPVBORn"
      },
      "source": [
        "# ENCODING"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  Encoding Structures Using MPNN\n",
        "\n",
        "Before performing any search or alignment, we **embed all protein structures** using a Message Passing Neural Network (MPNN).\n",
        "\n",
        "- This step transforms raw 3D coordinates and masks into **learned feature representations**.\n",
        "- These embeddings are stored  and are reused during the search process.\n",
        "- The encoding is **performed once**, which makes future computations faster and more efficient.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "sWITzLWHN7rQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "MqcTtNJKZDZe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb3f626e-1ece-4a01-9610-26a57e9ad846",
        "cellView": "form"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_size set to: 1419\n"
          ]
        }
      ],
      "source": [
        "# @title Prepare data\n",
        "# @title Default title text\n",
        "key = jax.random.PRNGKey(0)\n",
        "\n",
        "num_layers = 3\n",
        "num_neighbors = 64\n",
        "encoding_dim = 64\n",
        "categorical = False\n",
        "nb_clusters = 20\n",
        "\n",
        "\n",
        "def enco_(x1,node_features = encoding_dim,\n",
        "                 edge_features = encoding_dim, hidden_dim = encoding_dim,\n",
        "                 num_encoder_layers=num_layers,\n",
        "                  k_neighbors=num_neighbors,categorical = categorical,nb_clusters = nb_clusters):\n",
        "  if categorical:\n",
        "      a = enco.ENCODING_KMEANS_SEQ(node_features,edge_features,hidden_dim,num_encoder_layers,k_neighbors,nb_clusters = nb_clusters)\n",
        "\n",
        "  else:\n",
        "\n",
        "    a = enco.ENCODING(node_features,edge_features,hidden_dim,num_encoder_layers,k_neighbors)\n",
        "  return a(x1)\n",
        "\n",
        "ENCO = hk.transform(enco_)\n",
        "@jax.jit\n",
        "def enco_fast(params,key,input_data):\n",
        "  return ENCO.apply(params,key,input_data)\n",
        "\n",
        "X1s = []\n",
        "mask1s = []\n",
        "chain1s = []\n",
        "res1s = []\n",
        "\n",
        "id1s = []\n",
        "l1 = []\n",
        "\n",
        "for k in dicti_inputs.keys():\n",
        "    pr1 = k\n",
        "    _X1, _mask1, _chain1, _res1 = dicti_inputs[pr1]\n",
        "    id1s.append(pr1)\n",
        "    X1s.append(_X1[0])\n",
        "    mask1s.append(_mask1[0])\n",
        "    chain1s.append(_chain1[0])\n",
        "    res1s.append(_res1[0])\n",
        "    l1.append(len(_X1[0]))\n",
        "\n",
        "max_len = max(l1)\n",
        "\n",
        "# NOTE: If max_size is too large, consider splitting your data into smaller chunks\n",
        "\n",
        "print(f\"max_size set to: {max_len}\")\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "lBxMrG82VLjK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2b1e8689-61f0-4fe3-b11b-11ee61b4bad4",
        "cellView": "form"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "241.62516736984253\n"
          ]
        }
      ],
      "source": [
        "# @title Create encodings\n",
        "ENCOO = hk.transform(enco_)\n",
        "encodings = []\n",
        "# Set batch size\n",
        "bs = 10\n",
        "num_samples = len(X1s)\n",
        "\n",
        "# Convert lists to numpy arrays\n",
        "X1s = np.array(X1s,dtype=object)\n",
        "mask1s = np.array(mask1s,dtype=object)\n",
        "res1s = np.array(res1s,dtype=object)\n",
        "chain1s = np.array(chain1s,dtype=object)\n",
        "\n",
        "key = jax.random.PRNGKey(42)\n",
        "\n",
        "# Start timer\n",
        "beg = time.time()\n",
        "\n",
        "# Loop over batches\n",
        "for i in range(num_samples // bs):\n",
        "    # Pad the current batch\n",
        "    X1, mask1, res1, chain1, X2, mask2, res2, chain2, lens = utils.pad_(\n",
        "        X1s[i * bs:(i + 1) * bs], mask1s[i * bs:(i + 1) * bs], res1s[i * bs:(i + 1) * bs], chain1s[i * bs:(i + 1) * bs],\n",
        "        X1s[i * bs:(i + 1) * bs], mask1s[i * bs:(i + 1) * bs], res1s[i * bs:(i + 1) * bs], chain1s[i * bs:(i + 1) * bs],\n",
        "        max_len\n",
        "    )\n",
        "    input_data = X2, mask2, res2, chain2\n",
        "    encodings_ = enco_fast(params, key, input_data)\n",
        "\n",
        "    # Directly extend the encodings list with the results\n",
        "    encodings.extend(encodings_)\n",
        "\n",
        "# Process the remaining samples if any\n",
        "if num_samples % bs != 0:\n",
        "    X1, mask1, res1, chain1, X2, mask2, res2, chain2, lens = utils.pad_(\n",
        "        X1s[num_samples - num_samples % bs:], mask1s[num_samples - num_samples % bs:], res1s[num_samples - num_samples % bs:],\n",
        "        chain1s[num_samples - num_samples % bs:], X1s[num_samples - num_samples % bs:], mask1s[num_samples - num_samples % bs:],\n",
        "        res1s[num_samples - num_samples % bs:], chain1s[num_samples - num_samples % bs:], max_len\n",
        "    )\n",
        "    input_data = X2, mask2, res2, chain2\n",
        "    encodings_ = ENCOO.apply(params, key, input_data)\n",
        "    encodings.extend(encodings_)\n",
        "\n",
        "# End timing and print\n",
        "print(time.time() - beg)\n",
        "\n",
        "\n",
        "\n",
        "dicti_encodings = {}\n",
        "for l,k in enumerate(encodings):\n",
        "\n",
        "  dicti_encodings[id1s[l]] = k[:l1[l],:]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4YAE0XlYr7h4"
      },
      "source": [
        "#One-VS-all"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you're only interested in evaluating a single query structure against all the others in your dataset, you can run this section.\n",
        "\n",
        "It will compute the scores and save them in a .csv file for easy analysis.\n",
        "\n",
        "üìÑ Output: A CSV file containing the scores for all sequences compared to your query."
      ],
      "metadata": {
        "id": "g_4fnYikN7rT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "thresholds = np.arange(100,max_len+100,100)\n",
        "print(thresholds)\n",
        "reusable_target_data = search.setup_target_data(dicti_encodings, dicti_inputs,thresholds)\n",
        "query_id = \"d2dixa1\" # @param\n",
        "enc = dicti_encodings.get(query_id)\n",
        "\n",
        "if enc is None:\n",
        "    print(f\"Query ID '{query_id}' not found in dicti_encodings.\")\n",
        "else:\n",
        "    l_query = enc.shape[0]\n",
        "    l_query_pad = l_query\n",
        "\n",
        "    print(f\"Processing single query: {query_id} (length={l_query}), using padding {l_query_pad}\")\n",
        "\n",
        "    try:\n",
        "        search.compute_scores_for_query(\n",
        "            query_id=query_id,\n",
        "            target_data=reusable_target_data,\n",
        "            model_type=model_type,\n",
        "            l_query_pad=l_query_pad\n",
        "        )\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing {query_id}: {e}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "id": "LMoLLVfoAcRb",
        "outputId": "92448539-8daf-4e61-b594-a859813a5e0e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 100  200  300  400  500  600  700  800  900 1000 1100 1200 1300 1400\n",
            " 1500]\n",
            "--- Starting One-Time Target Setup ---\n",
            "Dispatching pre-processing for all buckets...\n",
            "Waiting for data to be moved to device...\n",
            "--- One-Time Setup Finished in 73.36 seconds ---\n",
            "Processing single query: d2dixa1 (length=73), using padding 73\n",
            "\n",
            "Processing query: d2dixa1\n",
            "(100,) (73,)\n",
            "(73, 100) (73, 100)\n",
            "(100,) (73,)\n",
            "(73, 100) (73, 100)\n",
            "(200,) (73,)\n",
            "(73, 200) (73, 200)\n",
            "(200,) (73,)\n",
            "(73, 200) (73, 200)\n",
            "(300,) (73,)\n",
            "(73, 300) (73, 300)\n",
            "(300,) (73,)\n",
            "(73, 300) (73, 300)\n",
            "(400,) (73,)\n",
            "(73, 400) (73, 400)\n",
            "(400,) (73,)\n",
            "(73, 400) (73, 400)\n",
            "(500,) (73,)\n",
            "(73, 500) (73, 500)\n",
            "(500,) (73,)\n",
            "(73, 500) (73, 500)\n",
            "(600,) (73,)\n",
            "(73, 600) (73, 600)\n",
            "(700,) (73,)\n",
            "(73, 700) (73, 700)\n",
            "(800,) (73,)\n",
            "(73, 800) (73, 800)\n",
            "(900,) (73,)\n",
            "(73, 900) (73, 900)\n",
            "(1000,) (73,)\n",
            "(73, 1000) (73, 1000)\n",
            "(1100,) (73,)\n",
            "(73, 1100) (73, 1100)\n",
            "(1200,) (73,)\n",
            "(73, 1200) (73, 1200)\n",
            "(1300,) (73,)\n",
            "(73, 1300) (73, 1300)\n",
            "(1400,) (73,)\n",
            "(73, 1400) (73, 1400)\n",
            "(1500,) (73,)\n",
            "(73, 1500) (73, 1500)\n",
            "‚úÖ Saved scores for d2dixa1 to `scores_sorted_d2dixa1.csv` in 21.86 seconds.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üîÑ All-vs-All Search\n",
        "\n",
        "This section performs a full all-vs-all comparison, where each encoded query is evaluated against all others in the dataset using the compute_scores_for_query function.\n",
        "\n",
        "Each query is treated as a search input, and scores are computed against a shared target set (reusable_target_data).\n"
      ],
      "metadata": {
        "id": "JOaD8tREBBCp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "thresholds = np.arange(100,max_len+100,100)\n",
        "print(thresholds)\n",
        "reusable_target_data = search.setup_target_data(dicti_encodings, dicti_inputs,thresholds)\n",
        "thresholds = np.arange(100, max_len + 100, 100)\n",
        "\n",
        "for threshold in thresholds:\n",
        "    min_len = threshold - 100\n",
        "    max_len = threshold\n",
        "    l_query_pad = threshold  # ou autre logique si besoin\n",
        "\n",
        "    print(f\"\\n=== Queries bt {min_len} and {max_len}  ===\")\n",
        "    compt = 0\n",
        "\n",
        "    for query_id, enc in dicti_encodings.items():\n",
        "        l_query = enc.shape[0]\n",
        "\n",
        "        if min_len <= l_query <= max_len:\n",
        "            compt += 1\n",
        "            print(f\"Processing query: {query_id} (length={l_query}), count={compt}\")\n",
        "            try:\n",
        "                search.compute_scores_for_query(\n",
        "                    query_id=query_id,\n",
        "                    target_data=reusable_target_data,\n",
        "                    model_type=model_type,\n",
        "                    l_query_pad=l_query_pad\n",
        "                )\n",
        "            except Exception as e:\n",
        "                print(f\"Error processing {query_id}: {e}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 426
        },
        "id": "Gm-y2FD0qaAs",
        "outputId": "c2ac25d0-0fce-401e-e35d-4b03ca616423"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 100  200  300  400  500  600  700  800  900 1000 1100 1200 1300 1400\n",
            " 1500]\n",
            "--- Starting One-Time Target Setup ---\n",
            "Dispatching pre-processing for all buckets...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-8-3096967117.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mthresholds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmax_len\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthresholds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mreusable_target_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msearch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetup_target_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdicti_encodings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdicti_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mthresholds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mthresholds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_len\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/SoftAlign/search.py\u001b[0m in \u001b[0;36msetup_target_data\u001b[0;34m(dicti_encodings, dicti_inputs, thresholds)\u001b[0m\n\u001b[1;32m    183\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m         \u001b[0menc2_all\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpad_enc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbucket_t\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m         \u001b[0mX_t_all\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpad_aux\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbucket_t\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m         \u001b[0mids_all\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m         \u001b[0mlengths_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/jax/_src/numpy/lax_numpy.py\u001b[0m in \u001b[0;36mstack\u001b[0;34m(arrays, axis, out, dtype)\u001b[0m\n\u001b[1;32m   4486\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"All input arrays must have the same shape.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4487\u001b[0m       \u001b[0mnew_arrays\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4488\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_arrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4489\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4490\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/jax/_src/numpy/lax_numpy.py\u001b[0m in \u001b[0;36mconcatenate\u001b[0;34m(arrays, axis, dtype)\u001b[0m\n\u001b[1;32m   4657\u001b[0m   \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m16\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4658\u001b[0m   \u001b[0;32mwhile\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays_out\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4659\u001b[0;31m     arrays_out = [lax.concatenate(arrays_out[i:i+k], axis)\n\u001b[0m\u001b[1;32m   4660\u001b[0m                   for i in range(0, len(arrays_out), k)]\n\u001b[1;32m   4661\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0marrays_out\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/jax/_src/numpy/lax_numpy.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   4657\u001b[0m   \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m16\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4658\u001b[0m   \u001b[0;32mwhile\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays_out\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4659\u001b[0;31m     arrays_out = [lax.concatenate(arrays_out[i:i+k], axis)\n\u001b[0m\u001b[1;32m   4660\u001b[0m                   for i in range(0, len(arrays_out), k)]\n\u001b[1;32m   4661\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0marrays_out\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/jax/_src/lax/lax.py\u001b[0m in \u001b[0;36mconcatenate\u001b[0;34m(operands, dimension)\u001b[0m\n\u001b[1;32m   1675\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mArray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1676\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1677\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mconcatenate_p\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0moperands\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdimension\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdimension\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1678\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1679\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/jax/_src/core.py\u001b[0m in \u001b[0;36mbind\u001b[0;34m(self, *args, **params)\u001b[0m\n\u001b[1;32m    500\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    501\u001b[0m     \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mskip_canonicalization\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcanonicalize_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 502\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_true_bind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    503\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    504\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_true_bind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/jax/_src/core.py\u001b[0m in \u001b[0;36m_true_bind\u001b[0;34m(self, *args, **params)\u001b[0m\n\u001b[1;32m    518\u001b[0m     \u001b[0mtrace_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meval_trace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 520\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind_with_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprev_trace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    521\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    522\u001b[0m       \u001b[0mtrace_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprev_trace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/jax/_src/core.py\u001b[0m in \u001b[0;36mbind_with_trace\u001b[0;34m(self, trace, args, params)\u001b[0m\n\u001b[1;32m    523\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mbind_with_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 525\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_primitive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    526\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mdef_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimpl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/jax/_src/core.py\u001b[0m in \u001b[0;36mprocess_primitive\u001b[0;34m(self, primitive, args, params)\u001b[0m\n\u001b[1;32m   1022\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mprimitive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind_with_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m       \u001b[0mcheck_eval_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1024\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mprimitive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimpl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1026\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mprocess_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprimitive\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtracers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/jax/_src/dispatch.py\u001b[0m in \u001b[0;36mapply_primitive\u001b[0;34m(prim, *args, **params)\u001b[0m\n\u001b[1;32m     88\u001b[0m   \u001b[0mprev\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjax_jit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mswap_thread_local_state_disable_jit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m   \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjax_jit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mswap_thread_local_state_disable_jit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprev\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "mount_file_id": "17jugX0Zkf6TzDnoXeOEMS4J0gHXX1oYU",
      "authorship_tag": "ABX9TyOCy49MIMpJuY6pW2h8reyo",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}